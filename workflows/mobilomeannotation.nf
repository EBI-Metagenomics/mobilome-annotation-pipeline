include { validateParameters ; paramsHelp ; samplesheetToList } from 'plugin/nf-schema'

/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    IMPORT MODULES
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

// Inputs preparing modules
include { RENAME           } from '../modules/rename_contigs'

// Annotation modules
include { PRODIGAL         } from '../modules/prodigal'
include { ARAGORN          } from '../modules/aragorn'
include { TRNAS_INTEGRATOR } from '../modules/trnas_integrator'
include { PROKKA           } from '../modules/prokka'
include { AMRFINDER_PLUS   } from '../modules/amrfinder_plus'

// Mobile genetic elements prediction modules
include { INTEGRONFINDER   } from '../modules/integronfinder'
include { ISESCAN          } from '../modules/isescan'
include { GENOMAD          } from '../modules/genomad'
include { VIRIFY_QC        } from '../modules/virify_qc'

// Results integration and writing modules
include { AMRFINDER_REPORT } from '../modules/amrfinder_report'
include { FASTA_WRITER     } from '../modules/fasta_writer'
include { GFF_MAPPING      } from '../modules/gff_mapping'
include { GFF_VALIDATOR    } from '../modules/gff_validator'
include { INTEGRATOR       } from '../modules/integrator'

/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    IMPORT SUBWORKFLOWS
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/
include { COMPOSITIONAL_OUTLIER_DETECTION } from '../subworkflows/compositional_outlier_detection'
include { ICEFINDER2_LITE                 } from '../subworkflows/icefinder2-lite'

// TODO: add diamond based annotation subworkflow for genes and pathofact modules


/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    RUN MAIN WORKFLOW
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

workflow MAIN {

    validateParameters()

    def ch_inputs = Channel.fromList(samplesheetToList(params.input, "./assets/schema_input.json"))

    /*
    ******************************************************************************************************
    * The code below is transforming the input channels to handle optional inputs, such as the
    * user-provided GFF files for user_proteins and virify.
    * Nextflow doesn't handle optional inputs well, so we use a common hack to provide an empty
    * array ([]) when the input is missing.
    * For the user_proteins_gff, if the file is present, we emit a tuple with the metadata and the
    * file path. If the file is missing, we emit a tuple with the metadata and an empty array ([]).
    * Similarly, for the virify_gff, if the file is present, we emit a tuple with the metadata and
    * the file path. If the file is missing, we emit a tuple with the metadata and an empty array ([]).
    ******************************************************************************************************
    */

    // The gff assembly can be provided by the user or generated by prokka
    // If provided by the user, then the option -run_prokka is disabled
    def to_append_gff_ch = ch_inputs.map { meta, _fasta, user_gff, _virify_gff -> {
            if ( user_gff ) {
                tuple(meta, user_gff, 'user')
		params.run_prokka = False
            } else {
                tuple(meta, [], null)
            }
        }
    }

    // PREPROCESSING
    RENAME( ch_inputs.map { meta, fasta, _user_proteins_gff, _virify_gff -> [meta, fasta] } )

    // PROKKA annotation is optional and is skipped by default.
    // When PROKKA annotation is activated, AMRfinder plus run as well
    def run_prodigal = true
    def assembly_faa_gff_ch = Channel.empty()
    def assembly_gff_ch = Channel.empty()
    if ( params.run_prokka ) {
        run_prodigal = false
        PROKKA( RENAME.out.contigs_1kb )
        assembly_faa_gff_ch = PROKKA.out.prokka_faa.join( PROKKA.out.prokka_gff )
        assembly_gff_ch = PROKKA.out.prokka_gff

        to_append_gff_ch = PROKKA.out.prokka_gff.map { meta, gff_file ->
            tuple(meta, gff_file, 'prokka')
        }

        def amr_finder_ch = PROKKA.out.prokka_fna.join( PROKKA.out.prokka_faa ).join( PROKKA.out.prokka_gff)

        AMRFINDER_PLUS( amr_finder_ch )
        AMRFINDER_REPORT(
            AMRFINDER_PLUS.out.amrfinder_tsv
            .join(
                INTEGRATOR.out.mobilome_prokka_gff
            ).join(
                RENAME.out.map_file
            ).join(
                user_proteins_ch
            )
        )
    }


    // We need CDS and tRNAs prediction for the MGEs QC
    // PROKKA gff output is suitable for this purpose
    // If user provides a gff, or PROKKA is off, we generate 
    // CDS and tRNAs annotation as we cannot rely on users 
    // input for our MGEs quality control
    if (run_prodigal) {
        PRODIGAL( RENAME.out.contigs_1kb )
        ARAGORN( RENAME.out.contigs_1kb )
        TRNAS_INTEGRATOR( ARAGORN.out.rnas_tbl.join( PRODIGAL.out.gff ).join( PRODIGAL.out.faa ) )
        assembly_faa_gff_ch = TRNAS_INTEGRATOR.out.merged_faa.join(TRNAS_INTEGRATOR.out.merged_gff)
        assembly_gff_ch = TRNAS_INTEGRATOR.out.merged_gff
    }

    // PREDICTION
    // Collecting ICEfinder2 databases
    db_ice_hmm_models = Channel.fromPath("${params.ice_hmm_models}.*", checkIfExists: true)
                        .collect()
                        .map { ice_db_files ->
                            [[id: file(params.ice_hmm_models).name ], ice_db_files]
                        }
    db_prokka_uniprot = Channel.fromPath("${params.prokka_uniprot_db}.*", checkIfExists: true)
                        .collect()
                        .map { uniprot_db_files ->
                            [[id: file(params.prokka_uniprot_db).name], uniprot_db_files]
                        }



    def icf2_inputs = RENAME.out.contigs_5kb.join(
        assembly_faa_gff_ch.map{meta, faa, _gff -> tuple(meta, faa) }
        ).join(
        assembly_faa_gff_ch.map{meta, _faa, gff -> tuple(meta, gff) }
        )

    ICEFINDER2_LITE( 
        icf2_inputs,
        db_ice_hmm_models, 
        params.ice_macsy_models, 
        db_prokka_uniprot
    )

    GENOMAD( RENAME.out.contigs_5kb )

    INTEGRONFINDER( RENAME.out.contigs_5kb )

    ISESCAN( RENAME.out.contigs_1kb )

    COMPOSITIONAL_OUTLIER_DETECTION( RENAME.out.contigs_100kb )


    // Parsing VIRify gff file when an input is provided
    def user_virify_gff_ch = ch_inputs.map { meta, _fasta, _user_gff, virify_gff -> {
           [meta, virify_gff]
        }
    }.filter { _meta, virify_gff -> virify_gff != [] }

    VIRIFY_QC( user_virify_gff_ch )


    /**********************************************************************************************
    * The INTEGRATOR step takes a bunch of outputs from the previous steps.
    * The following code is re-shaping the input to accommodate
    * optional inputs such as the user-provided GFF.
    * This is done this way because Nextflow doesn't handle optional inputs. One hack that the
    * community uses for inputs of type path is to provide an empty array ([]). So, we first
    * join with user-provided GFF with the remainder, try to get an empty element, and then we use map
    * to transform the null to [].
    ***********************************************************************************************/
    def integrator_ch = 
        assembly_gff_ch
    .join(
        RENAME.out.map_file
    ).join(
        ISESCAN.out.iss_tsv
    ).join(
        INTEGRONFINDER.out.contigs_summary
    ).join(
        INTEGRONFINDER.out.contigs_gbks
    ).join(
        ICEFINDER2_LITE.out.ices_tsv, remainder: true
    ).join(
        GENOMAD.out.genomad_vir
    ).join(
        GENOMAD.out.genomad_plas
    ).join(
        COMPOSITIONAL_OUTLIER_DETECTION.out.bed, remainder: true
    ).join(
        VIRIFY_QC.out.virify_hq, remainder: true
    )

    INTEGRATOR(
        integrator_ch.map {
            meta,
            assem_gff, 
            map_file, 
            iss_tsv, 
            contigs_summary, 
            gbks, 
            ices_tsv, 
            genomad_vir, 
            genomad_plas, 
            compos_bed, 
            virify_hq 
                -> {[
                meta, 
                assem_gff,
                map_file, 
                iss_tsv, 
                contigs_summary, 
                gbks, 
                ices_tsv ? ices_tsv : [], 
                genomad_vir, 
                genomad_plas, 
                compos_bed ? compos_bed : [], 
                virify_hq ? virify_hq : [] 
            ]}
        }
    )

    // POSTPROCESSING
    // Writing fasta file
    FASTA_WRITER(
        ch_inputs.map { meta, fasta, _user_proteins_gff, _virify_gff -> [meta, fasta] }
        .join(
            INTEGRATOR.out.mobilome_gff 
        )
    )

    if ( params.gff_validation ) {
        GFF_VALIDATOR( INTEGRATOR.out.mobilome_gff )
    }


    // Merging genes annotation on user gff or prokka, when available
    valid_to_append_gff_ch = to_append_gff_ch.filter { meta, gff_file, label ->
        gff_file && !gff_file.isEmpty() && label != null
    }

    if (valid_to_append_gff_ch)  { 
        valid_to_append_gff_ch.view()
        GFF_MAPPING(
            INTEGRATOR.out.mobilome_gff.join( valid_to_append_gff_ch ) 
        )
    }

}
